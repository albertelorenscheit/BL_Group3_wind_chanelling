{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as ddf\n",
    "import re\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from channeling_lib import AWS_file_loader, load_path, filter_data_based_on_time\n",
    "\n",
    "stations_str = ['Tom Joad','Rosanna','Bette Davis', 'Layla', 'Mrs Robinson']\n",
    "\n",
    "# TinyTag_str = ['CEB_1', 'CEB_2', 'CEB_3', 'CEB_4', 'CEB_5', 'TH1', 'TH2', 'TH3', 'TH5', 'TH6', 'TH8', 'TT1', 'TT2', 'TT3', 'TT4', 'TT5', 'TT6', 'TT7', 'TT9', 'TT12', 'TT13', 'TT14', 'TT15', 'TT16', 'TT17', 'TT18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = load_path()+'RawData/TinyTag/'\n",
    "\n",
    "instrument_textbook_name = load_path()+'instrument_textbook_BLcourse_spring2025(BL instruments).csv'\n",
    "instrument_textbook_data = pd.read_csv(instrument_textbook_name, encoding='latin1')\n",
    "\n",
    "# instrument_textbook_data['Station name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting instrument textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code ensures consistency no matter what chnages in the excel file in sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station names (keep only prefix + number)\n",
    "instrument_textbook_data['Formatted Name'] = [\n",
    "    re.sub(r\"(TT|TH|CEB)(\\d+).*\", r\"\\1\\2\", name) if re.match(r\"(TT|TH|CEB)\\d+\", name) else name\n",
    "    for name in instrument_textbook_data['Station name']\n",
    "]\n",
    "\n",
    "# Find duplicate names\n",
    "duplicates = instrument_textbook_data['Formatted Name'].value_counts()\n",
    "duplicate_names = duplicates[duplicates > 1].index  # Names that appear more than once\n",
    "\n",
    "# Apply \"_low\" and \"_high\" based on \"Th height (m)\"\n",
    "for name in duplicate_names:\n",
    "    subset = instrument_textbook_data[instrument_textbook_data['Formatted Name'] == name]\n",
    "    \n",
    "    # Find the lowest and highest Th height\n",
    "    min_index = subset['Th height (m)'].idxmin()\n",
    "    max_index = subset['Th height (m)'].idxmax()\n",
    "    \n",
    "    # Rename them\n",
    "    instrument_textbook_data.loc[min_index, 'Formatted Name'] = f\"{name}_low\"\n",
    "    instrument_textbook_data.loc[max_index, 'Formatted Name'] = f\"{name}_high\"\n",
    "\n",
    "# Get final formatted list\n",
    "formatted_names = instrument_textbook_data['Formatted Name'].tolist()\n",
    "\n",
    "# formatted_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell can ONLY be run once. If the following line soudl be 're-run', restart the kernal and run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert 'Formatted Name' as the first column\n",
    "instrument_textbook_data.insert(0, 'Formatted Station Name', instrument_textbook_data.pop('Formatted Name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading start and end times of Tinytag for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TinyTag_str = instrument_textbook_data['Station name'].tolist()\n",
    "TinyTag_str = [s for s in formatted_names if s.startswith((\"TT\", \"TH\", \"CEB\"))]\n",
    "\n",
    "\n",
    "# TinyTag_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_times = {}\n",
    "\n",
    "for station in TinyTag_str:\n",
    "    setup_time_idx = pd.to_datetime(instrument_textbook_data.loc[instrument_textbook_data['Formatted Station Name'] == station, 'Setup time (UTC)'].values[0])\n",
    "\n",
    "    maintenance_start_time_idx = pd.to_datetime(instrument_textbook_data.loc[instrument_textbook_data['Formatted Station Name'] == station, 'Maintenance start time (UTC)'].values[0])\n",
    "\n",
    "    # maintenance_duration_idx = int(instrument_textbook_data.loc[instrument_textbook_data['Formatted Station Name'] == station, 'Maintenance duration (minutes)'].values[0])\n",
    "    maintenance_duration_value = instrument_textbook_data.loc[instrument_textbook_data['Formatted Station Name'] == station, 'Maintenance duration (minutes)'].values[0]\n",
    "    maintenance_duration_idx = int(maintenance_duration_value) if not pd.isna(maintenance_duration_value) else 0\n",
    "\n",
    "    retrieval_time_idx = pd.to_datetime(instrument_textbook_data.loc[instrument_textbook_data['Formatted Station Name'] == station, 'Retrieval time (UTC)'].values[0])\n",
    "\n",
    "    manual_times[station] = {\n",
    "            'setup_time': setup_time_idx,\n",
    "            'maintenance_start_time': maintenance_start_time_idx,\n",
    "            'maintenance_duration': maintenance_duration_idx,\n",
    "            'retrieval_time': retrieval_time_idx\n",
    "        }\n",
    "\n",
    "# manual_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading TinyTag  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TinyTag data is loaded using UNISasci function read_Tinytag(). The data is then loaded dynamically using load_TinyTag_folders() function (Alberte)\n",
    "\n",
    "- Calibration data\n",
    "    - ceb_calibration_data = load_TinyTag_folders(path, 'CEB', 'calibration')\n",
    "    - TH_calibration_data = load_TinyTag_folders(path, 'TH', 'calibration')\n",
    "    - TT_calibration_data = load_TinyTag_folders(path, 'TT', 'calibration')\n",
    "\n",
    "- Actual data\n",
    "    - ceb_data = load_TinyTag_folders(path, 'CEB', 'normal')\n",
    "    - TH_data = load_TinyTag_folders(path, 'TH', 'normal')\n",
    "    - TT_data = load_TinyTag_folders(path, 'TT', 'normal')\n",
    "\n",
    "\n",
    "Specific data is selected by:\n",
    "- tag_data['tag_i_normal_data']\n",
    "- tag_calibration_data['tag_i_calibration_data']\n",
    "\n",
    "Where i corresponds to the TinyTag number in teh raw data folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function from unis github\n",
    "def read_Tinytag(filename, sensor):\n",
    "    '''\n",
    "    Reads data from one or several data files from the Tinytag output files.\n",
    "\n",
    "    Parameters:\n",
    "    -------\n",
    "    filename: str\n",
    "        String with path to file(s)\n",
    "        If several files shall be read, specify a string including UNIX-style wildcards\n",
    "    sensor: str\n",
    "        One of \"TT\", \"TH\" or \"CEB\"\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        a pandas dataframe with time as index and the individual variables as columns.\n",
    "    '''\n",
    "\n",
    "    import dask.dataframe as ddf\n",
    "\n",
    "\n",
    "    if sensor == \"TT\":\n",
    "        df = ddf.read_csv(filename, delimiter=\"\\t\", skiprows=5, parse_dates=[1], date_format=\"%d %b %Y %H:%M:%S\", names=[\"RECORD\", \"TIMESTAMP\", \"T_black\", \"T_white\"], encoding = \"ISO-8859-1\")\n",
    "    elif sensor == \"TH\":\n",
    "        df = ddf.read_csv(filename, delimiter=\"\\t\", skiprows=5, parse_dates=[1], date_format=\"%d %b %Y %H:%M:%S\", names=[\"RECORD\", \"TIMESTAMP\", \"T\", \"RH\"], encoding = \"ISO-8859-1\")\n",
    "    elif sensor == \"CEB\":\n",
    "        df = ddf.read_csv(filename, delimiter=\"\\t\", skiprows=5, parse_dates=[1], date_format=\"%d %b %Y %H:%M:%S\", names=[\"RECORD\", \"TIMESTAMP\", \"T\"], encoding = \"ISO-8859-1\")\n",
    "    else:\n",
    "        assert False, 'Sensortype of Tinytag not known. Should be one of \"TT\", \"TH\" or \"CEB\".'\n",
    "\n",
    "    df = df.compute()\n",
    "    df.set_index(\"TIMESTAMP\", inplace=True)\n",
    "\n",
    "    for key in list(df.columns):\n",
    "        if key == \"RECORD\":\n",
    "            pass\n",
    "        else:\n",
    "            data = [float(i.split(\" \")[0]) for i in df[key]]\n",
    "            unit = df[key].iloc[0].split(\" \")[1]\n",
    "            if unit == \"Â°C\":\n",
    "                unit = \"degC\"\n",
    "            new_key = f\"{key}_{unit}\"\n",
    "\n",
    "            df[new_key] = data\n",
    "\n",
    "            df.drop(key, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all CEB_i folders inside TinyTag\n",
    "# folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f)) and f.startswith('CEB_')]\n",
    "\n",
    "# # Dictionary to store the datasets\n",
    "# calibration_data = {}\n",
    "\n",
    "# # Loop through each CEB_i folder\n",
    "# for folder in folders:\n",
    "#     folder_path = os.path.join(path, folder)\n",
    "    \n",
    "#     # Get all .txt files that start with \"CEB_i_calibration_\"\n",
    "#     files = [f for f in os.listdir(folder_path) if f.startswith(folder + \"_calibration_\") and f.endswith(\".txt\")]\n",
    "    \n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         # Run the read_Tinytag function\n",
    "#         dataset = read_Tinytag(file_path, 'CEB')\n",
    "        \n",
    "#         # Store the dataset in a dictionary using the folder name as the key\n",
    "#         calibration_data[f\"{folder}_calibration_data\"] = dataset\n",
    "\n",
    "# # Loop over the stored datasets and assign them as individual variables\n",
    "# for dataset_name in calibration_data.keys():\n",
    "#     globals()[dataset_name] = calibration_data[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TH\n",
    "# folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f)) and f.startswith('TH')]\n",
    "\n",
    "# # Dictionary to store the datasets\n",
    "# calibration_data = {}\n",
    "\n",
    "# for folder in folders:\n",
    "#     folder_path = os.path.join(path, folder)\n",
    "    \n",
    "#     # Get all .txt files that start with \"THi_calibration_\"\n",
    "#     files = [f for f in os.listdir(folder_path) if f.startswith(folder + \"_calibration_\") and f.endswith(\".txt\")]\n",
    "    \n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         # Run the read_Tinytag function\n",
    "#         dataset = read_Tinytag(file_path, 'TH')\n",
    "        \n",
    "#         # Store the dataset in a dictionary using the folder name as the key\n",
    "#         calibration_data[f\"{folder}_calibration_data\"] = dataset\n",
    "\n",
    "# for dataset_name in calibration_data.keys():\n",
    "#     globals()[dataset_name] = calibration_data[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TT\n",
    "# folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f)) and f.startswith('TT')]\n",
    "\n",
    "# # Dictionary to store the datasets\n",
    "# calibration_data = {}\n",
    "\n",
    "# for folder in folders:\n",
    "#     folder_path = os.path.join(path, folder)\n",
    "    \n",
    "#     # Get all .txt files that start with \"TTi_calibration_\"\n",
    "#     files = [f for f in os.listdir(folder_path) if f.startswith(folder + \"_calibration_\") and f.endswith(\".txt\")]\n",
    "    \n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         # Run the read_Tinytag function\n",
    "#         dataset = read_Tinytag(file_path, 'TT')\n",
    "        \n",
    "#         # Store the dataset in a dictionary using the folder name as the key\n",
    "#         calibration_data[f\"{folder}_calibration_data\"] = dataset\n",
    "\n",
    "# for dataset_name in calibration_data.keys():\n",
    "#     globals()[dataset_name] = calibration_data[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_TinyTag_folders(path, tag, datatype):\n",
    "    \"\"\"\n",
    "    Processes folders that start with a specific prefix, reads corresponding files,\n",
    "    and stores their datasets in a dictionary.\n",
    "    \"\"\"\n",
    "    # prefix = 0\n",
    "    # prefix = []\n",
    "    if tag == 'CEB':\n",
    "        prefix = 'CEB_'\n",
    "    elif tag == 'TH':\n",
    "        prefix = 'TH'\n",
    "    elif tag == 'TT':\n",
    "        prefix = 'TT'\n",
    "\n",
    "    if datatype == 'calibration':\n",
    "        folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f)) and f.startswith(prefix)]\n",
    "        calibration_data = {}\n",
    "\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(path, folder)\n",
    "            files = [f for f in os.listdir(folder_path) if f.startswith(f\"{folder}_calibration_\") and f.endswith(\".txt\")]\n",
    "            \n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                dataset = read_Tinytag(file_path, tag)  # Process the file\n",
    "                calibration_data[f\"{folder}_calibration_data\"] = dataset\n",
    "        \n",
    "        return calibration_data\n",
    "    \n",
    "    elif datatype == 'normal':\n",
    "        folders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f)) and f.startswith(prefix)]\n",
    "        normal_data = {}\n",
    "\n",
    "        for folder in folders:\n",
    "            folder_path = os.path.join(path, folder)\n",
    "            # Filter files that DO NOT contain \"_calibration\" in their name\n",
    "            files = [f for f in os.listdir(folder_path) if \"_calibration\" not in f and f.endswith(\".txt\")]\n",
    "            \n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                dataset = read_Tinytag(file_path, tag)  # Process the file\n",
    "                normal_data[f\"{folder}_normal_data\"] = dataset  # Different key to distinguish\n",
    "\n",
    "        return normal_data\n",
    "\n",
    "        \n",
    "# # Process all folder types\n",
    "# all_data = {}\n",
    "# for prefix, tag in zip([\"CEB_\", \"TH\", \"TT\"], [\"CEB\", \"TH\", \"TT\"]):\n",
    "#     all_data.update(load_TinyTag_folders(path, prefix, tag))\n",
    "\n",
    "# # Assign the datasets to global variables\n",
    "# globals().update(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD</th>\n",
       "      <th>T_degC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-26 15:18:44</th>\n",
       "      <td>1</td>\n",
       "      <td>15.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 15:19:44</th>\n",
       "      <td>2</td>\n",
       "      <td>15.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 15:20:44</th>\n",
       "      <td>3</td>\n",
       "      <td>15.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 15:21:44</th>\n",
       "      <td>4</td>\n",
       "      <td>15.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26 15:22:44</th>\n",
       "      <td>5</td>\n",
       "      <td>15.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 09:22:44</th>\n",
       "      <td>11165</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 09:23:44</th>\n",
       "      <td>11166</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 09:24:44</th>\n",
       "      <td>11167</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 09:25:44</th>\n",
       "      <td>11168</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-03 09:26:44</th>\n",
       "      <td>11169</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11169 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RECORD  T_degC\n",
       "TIMESTAMP                          \n",
       "2025-01-26 15:18:44       1   15.29\n",
       "2025-01-26 15:19:44       2   15.93\n",
       "2025-01-26 15:20:44       3   15.84\n",
       "2025-01-26 15:21:44       4   15.80\n",
       "2025-01-26 15:22:44       5   15.74\n",
       "...                     ...     ...\n",
       "2025-02-03 09:22:44   11165    0.05\n",
       "2025-02-03 09:23:44   11166    0.16\n",
       "2025-02-03 09:24:44   11167    0.17\n",
       "2025-02-03 09:25:44   11168    0.38\n",
       "2025-02-03 09:26:44   11169    3.42\n",
       "\n",
       "[11169 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceb_calibration_data = load_TinyTag_folders(path, 'CEB', 'calibration')\n",
    "TH_calibration_data = load_TinyTag_folders(path, 'TH', 'calibration')\n",
    "TT_calibration_data = load_TinyTag_folders(path, 'TT', 'calibration')\n",
    "\n",
    "ceb_data = load_TinyTag_folders(path, 'CEB', 'normal')\n",
    "TH_data = load_TinyTag_folders(path, 'TH', 'normal')\n",
    "TT_data = load_TinyTag_folders(path, 'TT', 'normal')\n",
    "\n",
    "# ceb_calibration_data['CEB_1_calibration_data']\n",
    "\n",
    "ceb_data['CEB_1_normal_data']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boundary_layer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
